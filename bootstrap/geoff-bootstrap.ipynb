{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 3em; color: orange;\">BOOTSTRAP DAT</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GETTING THE DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass  survived                                             name     sex  \\\n",
      "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
      "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
      "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
      "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
      "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
      "\n",
      "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
      "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
      "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
      "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
      "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "\n",
      "                         home.dest  \n",
      "0                     St Louis, MO  \n",
      "1  Montreal, PQ / Chesterville, ON  \n",
      "2  Montreal, PQ / Chesterville, ON  \n",
      "3  Montreal, PQ / Chesterville, ON  \n",
      "4  Montreal, PQ / Chesterville, ON  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/Geoff/Desktop/Workspace/Dev/MS2/DAT/901/bootstrap/titanic.csv');\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass  survived                                             name     sex  \\\n",
      "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
      "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
      "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
      "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
      "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
      "5       1         1                              Anderson, Mr. Harry    male   \n",
      "6       1         1                Andrews, Miss. Kornelia Theodosia  female   \n",
      "7       1         0                           Andrews, Mr. Thomas Jr    male   \n",
      "8       1         1    Appleton, Mrs. Edward Dale (Charlotte Lamson)  female   \n",
      "9       1         0                          Artagaveytia, Mr. Ramon    male   \n",
      "\n",
      "       age  sibsp  parch    ticket      fare    cabin embarked boat   body  \\\n",
      "0  29.0000      0      0     24160  211.3375       B5        S    2    NaN   \n",
      "1   0.9167      1      2    113781  151.5500  C22 C26        S   11    NaN   \n",
      "2   2.0000      1      2    113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "3  30.0000      1      2    113781  151.5500  C22 C26        S  NaN  135.0   \n",
      "4  25.0000      1      2    113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "5  48.0000      0      0     19952   26.5500      E12        S    3    NaN   \n",
      "6  63.0000      1      0     13502   77.9583       D7        S   10    NaN   \n",
      "7  39.0000      0      0    112050    0.0000      A36        S  NaN    NaN   \n",
      "8  53.0000      2      0     11769   51.4792     C101        S    D    NaN   \n",
      "9  71.0000      0      0  PC 17609   49.5042      NaN        C  NaN   22.0   \n",
      "\n",
      "                         home.dest  \n",
      "0                     St Louis, MO  \n",
      "1  Montreal, PQ / Chesterville, ON  \n",
      "2  Montreal, PQ / Chesterville, ON  \n",
      "3  Montreal, PQ / Chesterville, ON  \n",
      "4  Montreal, PQ / Chesterville, ON  \n",
      "5                     New York, NY  \n",
      "6                       Hudson, NY  \n",
      "7                      Belfast, NI  \n",
      "8              Bayside, Queens, NY  \n",
      "9              Montevideo, Uruguay  \n",
      "age 1046 non-null 263 null\n"
     ]
    }
   ],
   "source": [
    "def info_age():\n",
    "    nonNull = len(data) - data['age'].isna().sum()\n",
    "    print(data.head(10))\n",
    "    print('age', nonNull, 'non-null', data['age'].isna().sum(), 'null')\n",
    "info_age()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACTING STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 500\n",
      "age: 28.918\n",
      "fare: 28.918\n"
     ]
    }
   ],
   "source": [
    "def survived_only():\n",
    "    print(\"total:\", data['survived'].sum())\n",
    "    print('age:', data.loc[(data['survived'] == 1), 'age'].mean().round(3)))\n",
    "    print('fare:', data.loc[(data['survived'] == 1), 'fare'].mean().round(3))\n",
    "    # ageSurvived = data.groupby('survived')['age'].mean()\n",
    "    # fareSurvived = data.groupby('survived')['fare'].mean()\n",
    "    # print(\"age:\", ageSurvived[1].round(3))\n",
    "    # print(\"fare:\", fareSurvived[1].round(3))\n",
    "    # df = pd.DataFrame(\n",
    "    # {\n",
    "    #     \"total:\": [\"test\"],\n",
    "    #     \"age:\": [\"test\"],\n",
    "    #     \"fare:\": [\"test\"],\n",
    "    # })\n",
    "    # print(df)\n",
    "survived_only()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROUPS ALONG CHARACTERISTICS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived: 0.3819709702062643\n",
      "Age Survived: 28.918\n",
      "sex\n",
      "female    0.727468\n",
      "male      0.190985\n",
      "Name: survived, dtype: float64 \n",
      "\n",
      "pclass\n",
      "1    0.619195\n",
      "2    0.429603\n",
      "3    0.255289\n",
      "Name: survived, dtype: float64 \n",
      "\n",
      "sex     pclass\n",
      "female  1         0.965278\n",
      "        2         0.886792\n",
      "        3         0.490741\n",
      "male    1         0.340782\n",
      "        2         0.146199\n",
      "        3         0.152130\n",
      "Name: survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def probality_surviving():\n",
    "    print('Survived:', data['survived'].mean())\n",
    "    print('Age Survived:',  data.loc[(data['survived'] == 1), 'age'].mean().round(3))\n",
    "    # print('Male Survived:', data[data['sex'] == 'male']['survived'].mean())\n",
    "    # print('Female Survived:', data[data['sex'] == 'female']['survived'].mean())\n",
    "    # print('Pclass 1 Survived:', data[data['pclass'] == 1]['survived'].mean())\n",
    "    # print('Pclass 2 Survived:', data[data['pclass'] == 2]['survived'].mean())\n",
    "    # print('Pclass 3 Survived:', data[data['pclass'] == 3]['survived'].mean())\n",
    "    # print('Pclass 1 & Female:', data[(data['sex'] == 'female') & data['age'] & (data['pclass'] == 1)]['survived'].mean())\n",
    "    # print('Pclass 1 & Male:', data[(data['sex'] == 'male') & data['age'] & (data['pclass'] == 1)]['survived'].mean())\n",
    "    # print('Pclass 2 & Female:', data[(data['sex'] == 'female') & data['age'] & (data['pclass'] == 2)]['survived'].mean())\n",
    "    # print('Pclass 2 & Male:', data[(data['sex'] == 'male') & data['age'] & (data['pclass'] == 2)]['survived'].mean())\n",
    "    # print('Pclass 3 & Female:', data[(data['sex'] == 'female') & data['age'] & (data['pclass'] == 3)]['survived'].mean())\n",
    "    # print('Pclass 3 & Male:', data[(data['sex'] == 'male') & data['age'] & (data['pclass'] == 3)]['survived'].mean())\n",
    "    # print(data.groupby('sex'))\n",
    "    # print(data.groupby('sex').mean())\n",
    "    print(data.groupby('sex').mean()['survived'], '\\n')\n",
    "    print(data.groupby('pclass').mean()['survived'], '\\n')\n",
    "    print(data.groupby(['sex', 'pclass']).mean()['survived'])\n",
    "probality_surviving()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide grouping categories\n",
    "\n",
    "<div style=\"font-size: 15px\">\n",
    "<h3>TODO LIST</h3>\n",
    "<p>Transform your data in order to get interesting information about the ages: group them into wide categories\n",
    "(like 0-9, 10-19, . . . ) before making statistics. This is called coding the information.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def group_categories():\n",
    "    print(\"\\n\")\n",
    "group_categories();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WELCOME TO THE JUNGLE OF TRAIN SYSTEM DATA\n",
    "## WALKING THROUGH THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE_ID\n",
      "    service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0        9939       1        1          1         1       0         0       0   \n",
      "\n",
      "   start_date  end_date      date  exception_type    route_id  \\\n",
      "0    20200220  20200520  20200413               2  OCE1506035   \n",
      "\n",
      "                  trip_id  trip_headsign  direction_id  block_id  shape_id  \n",
      "0  OCESN037071R0100119847          37071             1       NaN       NaN  \n",
      "\n",
      "AGENCY_ID\n",
      "   agency_id agency_name               agency_url agency_timezone agency_lang  \\\n",
      "0     OCESN        SNCF  http://www.ter-sncf.com    Europe/Paris          fr   \n",
      "\n",
      "     route_id  route_short_name              route_long_name  route_desc  \\\n",
      "0  OCE1506035               NaN  Paris-Vernon-Rouen-Le Havre         NaN   \n",
      "\n",
      "   route_type  route_url  route_color  route_text_color  \n",
      "0           2        NaN          NaN               NaN  \n",
      "\n",
      "TRIPS_ID\n",
      "      route_id  service_id                 trip_id  trip_headsign  \\\n",
      "0  OCE1506035        9939  OCESN037071R0100119847          37071   \n",
      "\n",
      "   direction_id  block_id  shape_id arrival_time departure_time  \\\n",
      "0             1       NaN       NaN     23:05:00       23:05:00   \n",
      "\n",
      "                         stop_id  stop_sequence  stop_headsign  pickup_type  \\\n",
      "0  StopPoint:OCECar TER-87381509              0            NaN            0   \n",
      "\n",
      "   drop_off_type  shape_dist_traveled  \n",
      "0              0                  NaN  \n",
      "\n",
      "STOP_ID\n",
      "                   trip_id arrival_time departure_time  \\\n",
      "0  OCESN037071R0100119847     23:05:00       23:05:00   \n",
      "\n",
      "                         stop_id  stop_sequence  stop_headsign  pickup_type  \\\n",
      "0  StopPoint:OCECar TER-87381509              0            NaN            0   \n",
      "\n",
      "   drop_off_type  shape_dist_traveled                stop_name  stop_desc  \\\n",
      "0              0                  NaN  Gare de Mantes-la-Jolie        NaN   \n",
      "\n",
      "    stop_lat  stop_lon  zone_id  stop_url  location_type        parent_station  \n",
      "0  48.989687  1.703294      NaN       NaN              0  StopArea:OCE87381509  \n"
     ]
    }
   ],
   "source": [
    "df_calendar_dates = pd.read_csv('C:/Users/Geoff/Desktop/Workspace/Dev/MS2/DAT/901/bootstrap/data_sncf/calendar_dates.txt')\n",
    "df_calendar = pd.read_csv('C:/Users/Geoff/Desktop/Workspace/Dev/MS2/DAT/901/bootstrap/data_sncf/calendar.txt')\n",
    "df_trips = pd.read_csv('C:/Users/Geoff/Desktop/Workspace/Dev/MS2/DAT/901/bootstrap/data_sncf/trips.txt')\n",
    "df_stop_times = pd.read_csv('C:/Users/Geoff/Desktop/Workspace/Dev/MS2/DAT/901/bootstrap/data_sncf/stop_times.txt')\n",
    "df_stops = pd.read_csv('C:/Users/Geoff/Desktop/Workspace/Dev/MS2/DAT/901/bootstrap/data_sncf/stops.txt')\n",
    "df_agency = pd.read_csv('C:/Users/Geoff/Desktop/Workspace/Dev/MS2/DAT/901/bootstrap/data_sncf/agency.txt')\n",
    "df_routes = pd.read_csv('C:/Users/Geoff/Desktop/Workspace/Dev/MS2/DAT/901/bootstrap/data_sncf/routes.txt')\n",
    "calendar_merge = pd.merge(df_calendar, df_calendar_dates, on=\"service_id\")\n",
    "calendar_trips_merge = pd.merge(calendar_merge, df_trips, on=\"service_id\")\n",
    "trips_stop_merge = pd.merge(df_trips, df_stop_times, on=\"trip_id\")\n",
    "agency_route_merge = pd.merge(df_agency, df_routes, on=\"agency_id\")\n",
    "stop_merge = pd.merge(df_stop_times, df_stops, on=\"stop_id\")\n",
    "print(\"SERVICE_ID\\n\", calendar_trips_merge.head(1))\n",
    "print(\"\\nAGENCY_ID\\n\", agency_route_merge.head(1))\n",
    "print(\"\\nTRIPS_ID\\n\", trips_stop_merge.head(1))\n",
    "print(\"\\nSTOP_ID\\n\", stop_merge.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"font-size: 15px\">\n",
    "<h1>TODO LIST</h1>\n",
    "<p>Find out if one can catch a train from a given place (Paris - Gare de l’est). For that purpose, you might need\n",
    "two different tables. Identify these tables, load them into dataframes and play around with them.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex: 209129 entries, 0 to 209128\n",
      "Data columns (total 9 columns)\n",
      "trip_id 209129 non-null object\n",
      "arrival_time 209129 non-null object\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "def info_trains_part_1():\n",
    "    print('RangeIndex:', df_stop_times['shape_dist_traveled'].isna().sum(), 'entries, 0 to', df_stop_times['shape_dist_traveled'].isna().sum() - 1)\n",
    "    print('Data columns (total', 9,'columns)')\n",
    "    print('trip_id', df_stop_times['shape_dist_traveled'].isna().sum(), 'non-null', df_stop_times['arrival_time'].dtypes)\n",
    "    print('arrival_time', df_stop_times['shape_dist_traveled'].isna().sum(), 'non-null', df_stop_times['arrival_time'].dtypes)\n",
    "    print('...')\n",
    "info_trains_part_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEED TO USE APPEND FOR TESTING AND ADDING 9 COLUMNS ONLY \n",
    "<ref style=\"font-size: 20px; color: red;\">-> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.append.html<ref/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERGING INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "def info_trains_part_2():\n",
    "    print('end')\n",
    "info_trains_part_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 15px\">\n",
    "<h1>TODO LIST</h1>\n",
    "<p>Merge your two tables in such a way that stations are now identified by their full name. Check out for the names, indices and columns of the resulting new dataframe.<p/>\n",
    "<p>Merging dataframes may lead to automatic re-indexing, even with a clean join. Watch\n",
    "out for your index numbers.</p>\n",
    "<p>Once you have a clean table, keep only the trains that leave Paris - Gare de l’est, in the morning before\n",
    "10:00. Display, as a dataframe, their ids and departure time.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_id departure_time\n",
      "143417 OCESN839553F4704738345 08:42:00\n",
      "143472 OCESN839553F2802838334 08:42:00\n",
      "143499 OCESN839561F0800838467 05:42:00\n",
      "143590 OCESN839551F3403438301 06:34:00\n",
      "143599 OCESN839589F0500538521 07:42:00\n",
      "... ... ...\n",
      "149365 OCESN839130F0700738016 07:54:00\n",
      "149372 OCESN839130F0200238015 07:54:00\n",
      "149379 OCESN839134F0400438032 09:23:00\n",
      "149386 OCESN839132F0300338026 08:54:00\n",
      "150356 OCESN839573F2102138483 08:21:00\n",
      "[70 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"trip_id departure_time\\n143417 OCESN839553F4704738345 08:42:00\\n143472 OCESN839553F2802838334 08:42:00\\n143499 OCESN839561F0800838467 05:42:00\\n143590 OCESN839551F3403438301 06:34:00\\n143599 OCESN839589F0500538521 07:42:00\\n... ... ...\\n149365 OCESN839130F0700738016 07:54:00\\n149372 OCESN839130F0200238015 07:54:00\\n149379 OCESN839134F0400438032 09:23:00\\n149386 OCESN839132F0300338026 08:54:00\\n150356 OCESN839573F2102138483 08:21:00\\n[70 rows x 2 columns]\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b68cdf6b187ffd965dd9ad9b2f176dd613b6e72c3cce25fc650cee44b3f3a8d2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
